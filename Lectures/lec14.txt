1. More C++, Gibbs Sampler.2. Building R packages.1. More OOP in C++.Wickham's page at http://adv-r.had.co.nz/Rcpp.html is an excellent resource.Gibbs sampler. Sometimes it can be tricky to simulate draws from a particular joint distribution of X and Y. A Gibbs sampler is a Markov chain Monte Carlo (MCMC) algorithm for generating a sequence of observations which are approximatelydraws from a specified multivariate probability distribution. It's a special case of the Metropolis–Hastings algorithm. A Gibbs sampler is useful when it's easier to sample from the conditionaldistribution of X given Y and the conditional dist of Y given X than it is to draw X and Y together from their joint distribution.Or more generally, you might want to draw a vector X = {x_1, ..., x_n}from its joint distribution p(x_1, ..., x_n).Start with some initial value X^(0) = {x_1^(0), ..., x_n^(0)}.Start with i = 1. Sample each x_1^(1) from the conditional dist.p(x_1|x_2^(0),...,x_n^(0)).Then sample x^2^(1) from the conditional dist.p(x_2|x_1^(0),x_3^(0),...,x_n^(0)).etc.For each sample i in {1,...,k}, sample each variable x_j^{(i)} fromthe conditional distributionp(x_j|x_1^{(i)},...,x_{j-1}^{(i)},x_{j+1}^{(i-1)},...,x_n^{(i-1)}).It can be shown that, under quite general conditions, the samples you get from the Gibbs sampler approximate the joint distribution p eventually.However, you shouldn't trust the first few values because they might be influenced by your choice of starting values. So there is usually a burn-in period. Also, successive values of the Gibbs Sampler are generally highly correlated, so sometimes people take every 100th value, or something, when they want a sample of many vectors from the distribution p.You can see that implementing the Gibbs sampler requires a loop, and thus would be slow in R but fast in C or C++.The following case study updates an example blogged about by DirkEddelbuettel, illustrating the conversion of a Gibbs sampler in R to C++.The R and C++ code shown below is very similar (it only took a few minutesto convert the R version to the C++ version), but runs about 20 timesfaster.Suppose we want to sample X and Y from the joint dist.f(x,y) = k x^2 exp( -x y^2 - y^2 + 2y - 4x).Here the conditional distributions are easyf(x|y) = (x^2)*exp(-x*(4+y*y))               ## a Gamma densityf(y|x) = exp(-0.5*2*(x+1)*(y^2 - 2*y/(x+1))  ## a Gaussian densityThe R code is as follows:gibbs_r <- function(N, thin) {  mat <- matrix(nrow = N, ncol = 2)  x <- y <- 0  for (i in 1:N) {    for (j in 1:thin) {      x <- rgamma(1, 3, y * y + 4)      y <- rnorm(1, 1 / (x + 1), 1 / sqrt(2 * (x + 1)))    }    mat[i, ] <- c(x, y)  }  mat}This is straightforward to convert to C++.  ## install.packages("Rcpp")    library(Rcpp)  cppFunction('NumericMatrix gibbs_cpp(int N, int thin) {  NumericMatrix mat(N, 2);  double x = 0, y = 0;  for(int i = 0; i < N; i++) {    for(int j = 0; j < thin; j++) {      x = rgamma(1, 3, 1 / (y * y + 4))[0];      y = rnorm(1, 1 / (x + 1), 1 / sqrt(2 * (x + 1)))[0];    }    mat(i, 0) = x;    mat(i, 1) = y;  }  return(mat);}') From Wickham's website, benchmarking the two implementations yields:microbenchmark(  gibbs_r(100, 10),  gibbs_cpp(100, 10))#> Unit: microseconds#>                expr    min     lq  mean median     uq    max neval#>    gibbs_r(100, 10) 13,600 16,100 16602 16,400 16,900 21,700   100#>  gibbs_cpp(100, 10)    524    562   623    580    606  2,860   1002. Building R packages.See the pdf file of David Diez.